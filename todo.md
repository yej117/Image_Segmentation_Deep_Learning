# Overview of the timeline

**14th Dec. - 4th Jan.**: project choice, dataset pre-processing, maybe first simple model and objective

**4th Jan.**: Peer review session, each group present their status to another group

**4th Jan. - 25th Jan.**: Architecture, fine-tuning, preparation presentation

Recommendation schedule for deadlines:
- 9th Jan.: data preprocessing (Sebastian)
- 13th Jan.: image augmentation (Suman)
- 17th Jan.: segmentation (Yi-Jie)
- 22nd Jan.: compiling, validating, testing (Erwin)
- 24th Jan.: preparation of materials for final presentation


# To Do list
## Before Peer Review on 4th Jan. 
Main task: 
Find an **_intermediate target_**. It sounds a bit too hard to reach the target of cloud segmentation in six weeks.
So before the peer review, we should _choose the dataset_ and _have objectives_.

1. Look into different training datasets
2. Try to train them with some exist networks (for example, revising the [Image Segmentation tutorial](https://www.tensorflow.org/tutorials/images/segmentation) to train the dataset you find) 
3. List down your findings:
    - Datasets: What you find? How it works with the networks that you used? Any interesting notebooks you find? What might be the challenging part?
    - Possible networks: What kind of application the networks mostly used for? What are their architecture? Any explanation for them? (And feel free to upload the program you wrote, it would be nice for the other to test)
    - Any useful documents you think it might help our project
4. Have another discussion before 4th Jan.


## Before meeting with Luca on 18th Dec. 16:30
- All: Look into the [Image Segmentation tutorial](https://www.tensorflow.org/tutorials/images/segmentation) with [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) 
- EJ: Check how to link Colab with GitHub repository 
     * add file from github: simply click the [link](http://colab.research.google.com/github), check the buttom "Private Repositories einschlieÃŸen", and select this repository
     * push the file to github: file > Save a copy in Github
- Sebastian: Meeting tools (Zoom link creation) -- **[Put the link here everytime?](https://us05web.zoom.us/j/81062250132?pwd=b3Nqc1A3aE9idkJGY2R6NHZHQWhUZz09)**
- Suman: Look into the dataset from Kaggle and give a brief summary
- Erwin: Work through the dataset from Kaggle and the possible applications
